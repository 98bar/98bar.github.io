<!DOCTYPE html>
<html lang="zh-CN">


<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
  <meta name="theme-color" content="#202020"/>
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  
    <meta name="keywords" content="机器学习,深度学习,强化学习," />
  

  
    <meta name="description" content="心向大海" />
  
  
  
  <link rel="icon" type="image/x-icon" href="/images/favicon.ico">
  
  <title>机器学习系列（四）逻辑回归 - 心向大海</title>
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="/css/pure-min.css">
    
      <link rel="stylesheet" href="/css/xoxo.css">
    
  
<meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="心向大海" type="application/atom+xml">
</head>


<body>
<div class="nav-container">
<nav class="home-menu pure-menu pure-menu-horizontal">
  <a class="pure-menu-heading" href="/">
    
      <img class="avatar" src="https://smiler666.github.io/images/favicon.ico">
    
    <span class="title" style="text-transform:none">心向大海</span>
  </a>

  <ul class="pure-menu-list clearfix">
      
          
            
              <li class="pure-menu-item"><a href="/" class="pure-menu-link">首页</a></li>
            
          
      
          
            
              <li class="pure-menu-item"><a href="/archives" class="pure-menu-link">文章</a></li>
            
          
      
          
            
              <li class="pure-menu-item"><a href="/post/share-1/" class="pure-menu-link">工具</a></li>
            
          
      
          
            
              <li class="pure-menu-item"><a href="/about" class="pure-menu-link">关于</a></li>
            
          
      
          
            
              <li class="pure-menu-item"><a href="/search" class="pure-menu-link">搜索</a></li>
            
          
      
  </ul>
   
</nav>

</div>

<div class="container" id="content-outer">
<div class="inner" id="content-inner">
<div class="post-container">
  <article class="post" id="post">
    <header class="post-header text-center">
      <h1 class="title">
        机器学习系列（四）逻辑回归
      </h1>
      <span>
        
        <time class="time" datetime="2021-03-25T04:20:00.000Z">
        2021-03-25
      </time>
        
      </span>
      <span class="slash">/</span>
      <span class="post-meta">
      <span class="post-tags">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" rel="tag">强化学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li></ul>
      </span>
    </span>
      <span class="slash">/</span>
      <span class="read">阅读耗时 6 分钟</span>
    </header>

    <div class="post-content">
      <a id="more"></a>
<h1 id="第4章：逻辑回归"><a href="#第4章：逻辑回归" class="headerlink" title="第4章：逻辑回归"></a>第4章：逻辑回归</h1><p>逻辑回归是一种常用于分类的线性模型。它的主要思想是通过对线性函数的值进行逻辑变换，将连续的输出转换为二元分类的概率值。逻辑回归常用于二分类问题，也可以扩展到多分类问题。在本文中，主要讨论二分类问题。</p>
<h2 id="4-1-线性函数"><a href="#4-1-线性函数" class="headerlink" title="4.1 线性函数"></a>4.1 线性函数</h2><p>从线性函数开始。线性函数是指变量之间的关系可以用一个线性方程来描述的函数。对于二维平面上的数据，线性函数的一般形式为：</p>
<script type="math/tex; mode=display">
f(x) = w_0 + w_1 x_1 + w_2 x_2</script><p>其中，$w_0$ 表示截距，$w_1$ 和 $w_2$ 分别表示两个自变量 $x_1$ 和 $x_2$ 的系数。可以将 $f(x)$ 表示成向量的内积形式：</p>
<script type="math/tex; mode=display">
f(x) = \boldsymbol{w}^T \boldsymbol{x}</script><p>其中，$\boldsymbol{w}$ 和 $\boldsymbol{x}$ 都是列向量。</p>
<h2 id="4-2-逻辑函数"><a href="#4-2-逻辑函数" class="headerlink" title="4.2 逻辑函数"></a>4.2 逻辑函数</h2><p>逻辑函数也被称为 sigmoid 函数。它将任意实数值映射到区间 $(0, 1)$，可以用以下公式表示：</p>
<script type="math/tex; mode=display">
\sigma(z) = \frac{1}{1 + e^{-z}}</script><p>其中，$z$ 是逻辑函数的自变量。逻辑函数的取值范围为 $(0, 1)$，当 $z$ 接近于正无穷时，$\sigma(z)$ 接近于 $1$，表示正例的概率很大；当 $z$ 接近于负无穷时，$\sigma(z)$ 接近于 $0$，表示负例的概率很大。</p>
<h2 id="4-3-逻辑回归模型"><a href="#4-3-逻辑回归模型" class="headerlink" title="4.3 逻辑回归模型"></a>4.3 逻辑回归模型</h2><p>逻辑回归模型是在线性函数的基础上加上一个逻辑函数的变换。它的表达式为：</p>
<script type="math/tex; mode=display">
h_{\boldsymbol{w}}(\boldsymbol{x}) = \sigma(\boldsymbol{w}^T \boldsymbol{x})</script><p>其中，$h_{\boldsymbol{w}}(\boldsymbol{x})$ 表示给定参数 $\boldsymbol{w}$ 和输入向量 $\boldsymbol{x}$，输出为正例的概率。为了方便，将 $h_{\boldsymbol{w}}(\boldsymbol{x})$ 表示为 $P(y=1|\boldsymbol{x};\boldsymbol{w})$，表示在给定 $\boldsymbol{x}$ 的情况下，$y=1$的概率，也就是正例的后验概率。类似地，$P(y=0|\boldsymbol{x};\boldsymbol{w})=1-P(y=1|\boldsymbol{x};\boldsymbol{w})$ 表示负例的后验概率。</p>
<p>可以使用最大似然估计来确定参数 $\boldsymbol{w}$。具体来说，对于给定的训练数据集 $\{(\boldsymbol{x}_1, y_1), (\boldsymbol{x}_2, y_2), …, (\boldsymbol{x}_m, y_m)\}$，似然函数为：</p>
<script type="math/tex; mode=display">
L(\boldsymbol{w}) = \prod_{i=1}^{m} P(y_i|\boldsymbol{x}_i;\boldsymbol{w})^{y_i} (1-P(y_i|\boldsymbol{x}_i;\boldsymbol{w}))^{1-y_i}</script><p>的目标是最大化似然函数。可以将其转换为最小化对数似然函数：</p>
<script type="math/tex; mode=display">
J(\boldsymbol{w}) = -\frac{1}{m} \sum_{i=1}^{m} [y_i \log h_{\boldsymbol{w}}(\boldsymbol{x}_i) + (1-y_i) \log (1-h_{\boldsymbol{w}}(\boldsymbol{x}_i))]</script><p>这个目标函数可以使用梯度下降法来最小化。具体地，对于每个参数 $w_j$，可以按照以下方式更新：</p>
<script type="math/tex; mode=display">
w_j := w_j - \alpha \frac{\partial J(\boldsymbol{w})}{\partial w_j}</script><p>其中，$\alpha$ 是学习率。</p>
<h2 id="4-4-例子"><a href="#4-4-例子" class="headerlink" title="4.4 例子"></a>4.4 例子</h2><p>下面来看一个简单的例子，使用逻辑回归模型对鸢尾花进行分类。使用 scikit-learn 库中的 iris 数据集。</p>
<p>首先，加载数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, :<span class="number">2</span>]</span><br><span class="line">y = (iris.target != <span class="number">0</span>) * <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>然后，将数据集分为训练集和测试集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<p>接下来，使用 scikit-learn 中的 LogisticRegression 模型来训练模型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">model = LogisticRegression()</span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure></p>
<p>最后，可以使用测试集来评估模型的性能：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line">accuracy_score(y_test, y_pred)</span><br></pre></td></tr></table></figure><br>在这个例子中，使用逻辑回归模型对鸢尾花进行了二分类，预测结果的准确率为 100%。</p>
<h2 id="4-5-总结"><a href="#4-5-总结" class="headerlink" title="4.5 总结"></a>4.5 总结</h2><p>逻辑回归是一种简单但常用的二分类算法。它通过将线性回归模型的输出通过一个逻辑函数进行压缩，得到一个概率值作为输出。我们可以使用梯度下降法来求解最优的参数。在实际应用中，逻辑回归通常与其他算法结合使用，来构建更复杂的分类器或预测模型。</p>

    </div>

  </article>
  <div class="toc-container">
    
  <div id="toc" class="toc-article">
    <strong class="toc-title">目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#第4章：逻辑回归"><span class="toc-text">第4章：逻辑回归</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-线性函数"><span class="toc-text">4.1 线性函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-逻辑函数"><span class="toc-text">4.2 逻辑函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3-逻辑回归模型"><span class="toc-text">4.3 逻辑回归模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4-例子"><span class="toc-text">4.4 例子</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-5-总结"><span class="toc-text">4.5 总结</span></a></li></ol></li></ol>
  </div>


  </div>
</div>
<div class="copyright">
    <span>本作品采用</span>
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh" target="_blank" rel="noopener">署名-非商业性使用-禁止演绎 4.0 国际许可协议</a>
    <span>进行许可。转载时请注明原文链接。</span>
</div>


  
    <div class="post-nav">
      <div class="post-nav-item post-nav-next">
        
          <span>〈 </span>
          <a href="/post/ai-0-ml-3/" rel="next" title="机器学习系列（三）回归模型">
          机器学习系列（三）回归模型
          </a>
        
      </div>
  
      <div class="post-nav-item post-nav-prev">
          
          <a href="/post/ai-0-ml-5/" rel="prev" title="机器学习系列（五）贝叶斯算法">
            机器学习系列（五）贝叶斯算法
          </a>
          <span>〉</span>
        
      </div>
    </div>
  



</div>
</div>

<footer class="footer text-center">
    <div id="bottom-inner">
        <a class="bottom-item" href="" target="_blank">心向大海</a> |
        <a class="bottom-item">Powered by hexo</a> |
        <a class="bottom-item">Copyright © 2023</a>  |
        <a>博客已运行<a id="days">0</a>天</a> 
        <script> 
        var s1 = '2020-04-15';//设置为你的建站时间 
        s1 = new Date(s1.replace(/-/g, "/")); 
        s2 = new Date(); 
        var days = s2.getTime() - s1.getTime(); 
        var number_of_days = parseInt(days / (1000 * 60 * 60 * 24)); 
        document.getElementById('days').innerHTML = number_of_days; 
        </script> |
        <a class="bottom-item" href="/atom.xml">RSS</a>
        <script>
			var _hmt = _hmt || [];
			(function() {
			  var hm = document.createElement("script");
			  hm.src = "https://hm.baidu.com/hm.js?7241c66da4c19bc02e939e6776919ff8";
			  var s = document.getElementsByTagName("script")[0]; 
			  s.parentNode.insertBefore(hm, s);
			})();
		</script>
    </div>
</footer>



<script>
  (function(window, document, undefined) {

    var timer = null;

    function returnTop() {
      cancelAnimationFrame(timer);
      timer = requestAnimationFrame(function fn() {
        var oTop = document.body.scrollTop || document.documentElement.scrollTop;
        if (oTop > 0) {
          document.body.scrollTop = document.documentElement.scrollTop = oTop - 50;
          timer = requestAnimationFrame(fn);
        } else {
          cancelAnimationFrame(timer);
        }
      });
    }

    var hearts = [];
    window.requestAnimationFrame = (function() {
      return window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.oRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        function(callback) {
          setTimeout(callback, 1000 / 60);
        }
    })();
    init();

    function init() {
      css(".heart{z-index:9999;width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: absolute;}.heart:after{top: -5px;}.heart:before{left: -5px;}");
      attachEvent();
      gameloop();
      addMenuEvent();
    }

    function gameloop() {
      for (var i = 0; i < hearts.length; i++) {
        if (hearts[i].alpha <= 0) {
          document.body.removeChild(hearts[i].el);
          hearts.splice(i, 1);
          continue;
        }
        hearts[i].y--;
        hearts[i].scale += 0.004;
        hearts[i].alpha -= 0.013;
        hearts[i].el.style.cssText = "left:" + hearts[i].x + "px;top:" + hearts[i].y + "px;opacity:" + hearts[i].alpha + ";transform:scale(" + hearts[i].scale + "," + hearts[i].scale + ") rotate(45deg);background:" + hearts[i].color;
      }
      requestAnimationFrame(gameloop);
    }

    /**
     * 给logo设置点击事件
     * 
     * - 回到顶部
     * - 出现爱心
     */
    function attachEvent() {
      var old = typeof window.onclick === "function" && window.onclick;
      var logo = document.getElementById("logo");
      if (logo) {
        logo.onclick = function(event) {
          returnTop();
          old && old();
          createHeart(event);
        }
      }
      
    }

    function createHeart(event) {
      var d = document.createElement("div");
      d.className = "heart";
      hearts.push({
        el: d,
        x: event.clientX - 5,
        y: event.clientY - 5,
        scale: 1,
        alpha: 1,
        color: randomColor()
      });
      document.body.appendChild(d);
    }

    function css(css) {
      var style = document.createElement("style");
      style.type = "text/css";
      try {
        style.appendChild(document.createTextNode(css));
      } catch (ex) {
        style.styleSheet.cssText = css;
      }
      document.getElementsByTagName('head')[0].appendChild(style);
    }

    function randomColor() {
      // return "rgb(" + (~~(Math.random() * 255)) + "," + (~~(Math.random() * 255)) + "," + (~~(Math.random() * 255)) + ")";
      return "#F44336";
    }

    function addMenuEvent() {
      var menu = document.getElementById('menu-main-post');
      if (menu) {
        var toc = document.getElementById('toc');
        if (toc) {
          menu.onclick = function() {
            if (toc) {
              if (toc.style.display == 'block') {
                toc.style.display = 'none';
              } else {
                toc.style.display = 'block';
              }
            }
          };
        } else {
          menu.style.display = 'none';
        }
      }
    }

  })(window, document);
</script>






<script>
  (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      }
      else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
  })();
</script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>