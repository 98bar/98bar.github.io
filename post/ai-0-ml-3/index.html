<!DOCTYPE html>
<html lang="zh-CN">


<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
  <meta name="theme-color" content="#202020"/>
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  
    <meta name="keywords" content="机器学习,深度学习,强化学习," />
  

  
    <meta name="description" content="QH的博客" />
  
  
  
  <link rel="icon" type="image/x-icon" href="/images/favicon.ico">
  
  <title>机器学习系列（三）回归模型 - QH的博客</title>
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="/css/pure-min.css">
    
      <link rel="stylesheet" href="/css/xoxo.css">
    
  
<meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="QH的博客" type="application/atom+xml">
</head>


<body>
<div class="nav-container">
<nav class="home-menu pure-menu pure-menu-horizontal">
  <a class="pure-menu-heading" href="/">
    
      <img class="avatar" src="https://smiler666.github.io/images/favicon.ico">
    
    <span class="title" style="text-transform:none">QH的博客</span>
  </a>

  <ul class="pure-menu-list clearfix">
      
          
            
              <li class="pure-menu-item"><a href="/" class="pure-menu-link">首页</a></li>
            
          
      
          
            
              <li class="pure-menu-item pure-menu-has-children pure-menu-allow-hover">
            
              <a href="#" id="合集" class="pure-menu-link">合集</a>
              <ul class="pure-menu-children">
              
                  
                    <li class="pure-menu-item"><a href="/tags/探索/" style="color:#202020;" class="pure-menu-link">探索</a></li>
                  
              
                  
                    <li class="pure-menu-item"><a href="/categories/程序/" style="color:#202020;" class="pure-menu-link">程序</a></li>
                  
              
                  
                    <li class="pure-menu-item"><a href="/post/py-1/" style="color:#202020;" class="pure-menu-link">Python</a></li>
                  
              
                  
                    <li class="pure-menu-item"><a href="/categories/数值计算/" style="color:#202020;" class="pure-menu-link">数值计算</a></li>
                  
              
                  
                    <li class="pure-menu-item"><a href="/tags/机器学习/" style="color:#202020;" class="pure-menu-link">机器学习</a></li>
                  
              
                  
                    <li class="pure-menu-item"><a href="/tags/RITSS/" style="color:#202020;" class="pure-menu-link">Abaqus/RITSS</a></li>
                  
              
              </ul>
            </li>
          
      
          
            
              <li class="pure-menu-item"><a href="/archives" class="pure-menu-link">文章</a></li>
            
          
      
          
            
              <li class="pure-menu-item"><a href="/post/share-1/" class="pure-menu-link">工具</a></li>
            
          
      
          
            
              <li class="pure-menu-item"><a href="/about" class="pure-menu-link">关于</a></li>
            
          
      
          
            
              <li class="pure-menu-item"><a href="/search" class="pure-menu-link">搜索</a></li>
            
          
      
  </ul>
   
</nav>

</div>

<div class="container" id="content-outer">
<div class="inner" id="content-inner">
<div class="post-container">
  <article class="post" id="post">
    <header class="post-header text-center">
      <h1 class="title">
        机器学习系列（三）回归模型
      </h1>
      <span>
        
        <time class="time" datetime="2021-03-24T04:20:00.000Z">
        2021-03-24
      </time>
        
      </span>
      <span class="slash">/</span>
      <span class="post-meta">
      <span class="post-tags">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" rel="tag">强化学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li></ul>
      </span>
    </span>
      <span class="slash">/</span>
      <span class="read">阅读耗时 22 分钟</span>
    </header>

    <div class="post-content">
      <a id="more"></a>
<h1 id="第3章：回归模型"><a href="#第3章：回归模型" class="headerlink" title="第3章：回归模型"></a>第3章：回归模型</h1><p>回归问题是机器学习中的一种常见问题，其目的是建立一个数学模型，来描述一个或多个自变量（输入特征）和一个因变量（输出目标）之间的关系。回归问题的应用场景很多，例如预测房价、股票、销量、温度等。回归问题的难点在于如何选择合适的模型和参数，使得模型能够准确地拟合数据，并具有良好的泛化能力。</p>
<p>在本节中，将介绍两种常用的回归模型：线性回归和多项式回归，并使用Python代码来实现它们。</p>
<h2 id="3-1-线性回归模型"><a href="#3-1-线性回归模型" class="headerlink" title="3.1 线性回归模型"></a>3.1 线性回归模型</h2><p>线性回归模型是一种简单而又有效的回归模型，它假设自变量和因变量之间存在线性关系，即：</p>
<script type="math/tex; mode=display">y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + … + \beta_n x_n + \epsilon</script><p>其中，$y$是因变量，$x_1, x_2, …, x_n$是自变量，$\beta_0, \beta_1, …, \beta_n$是模型参数，$\epsilon$是误差项。线性回归模型的目标是通过最小化误差平方和（或者其他损失函数），来估计出最优的参数值。</p>
<p>参数估计有多种方法，例如最小二乘法、梯度下降法、牛顿法等。其中最常用的是最小二乘法，它可以通过求解正规方程（normal equation）来得到参数的闭式解（closed-form solution），即：</p>
<script type="math/tex; mode=display">\boldsymbol{\beta} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}</script><p>其中，$\boldsymbol{\beta}$是参数向量，$\mathbf{X}$是输入矩阵，$\mathbf{y}$是输出向量。最小二乘法的优点是计算简单，缺点是当输入变量很多时，矩阵求逆会很耗时，并且可能存在奇异矩阵（singular matrix）的情况。</p>
<p>梯度下降法是另一种常用的参数估计方法，它是一种迭代算法，每次沿着损失函数的负梯度方向更新参数值，直到收敛到一个局部最优解或满足停止条件。梯度下降法的优点是可以处理大规模数据集，并且可以适用于非线性模型，缺点是需要选择合适的学习率（learning rate）和迭代次数（iteration number），并且可能陷入局部最优解而非全局最优解。</p>
<p>例如，有一个数据集，包含了房屋的面积（平方米）和价格（万元）两个变量，想要建立一个线性回归模型来预测房价。可以使用以下代码来实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入必要的库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">np.random.seed(<span class="number">0</span>) <span class="comment"># 设置随机种子</span></span><br><span class="line">x = np.linspace(<span class="number">50</span>, <span class="number">150</span>, <span class="number">100</span>) <span class="comment"># 生成50到150之间的100个等间隔数值</span></span><br><span class="line">y = <span class="number">3</span> * x + <span class="number">10</span> + np.random.normal(<span class="number">0</span>, <span class="number">15</span>, <span class="number">100</span>) <span class="comment"># 生成y值，加入一些噪声</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建并拟合模型</span></span><br><span class="line">model = LinearRegression() <span class="comment"># 创建线性回归对象</span></span><br><span class="line">model.fit(x.reshape(<span class="number">-1</span>, <span class="number">1</span>), y) <span class="comment"># 拟合数据，注意x需要转换为二维数组</span></span><br><span class="line">print(<span class="string">'Intercept:'</span>, model.intercept_) <span class="comment"># 输出截距</span></span><br><span class="line">print(<span class="string">'Coefficient:'</span>, model.coef_) <span class="comment"># 输出系数</span></span><br><span class="line">equation = <span class="string">'y = &#123;:.2f&#125;x + &#123;:.2f&#125;'</span>.format(model.coef_[<span class="number">0</span>], model.intercept_)</span><br><span class="line">print(<span class="string">'Equation:'</span>, equation) <span class="comment"># 输出回归方程</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制拟合曲线和回归方程</span></span><br><span class="line">plt.scatter(x, y) <span class="comment"># 绘制散点图</span></span><br><span class="line">plt.plot(x, model.predict(x.reshape(<span class="number">-1</span>, <span class="number">1</span>)), <span class="string">'r'</span>, label=equation) <span class="comment"># 绘制拟合曲线，红色</span></span><br><span class="line">plt.xlabel(<span class="string">'Area'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Price'</span>)</span><br><span class="line">plt.legend() <span class="comment"># 添加图例显示回归方程</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输出结果如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Intercept: <span class="number">7.991020982270399</span></span><br><span class="line">Coefficient: [<span class="number">3.02720881</span>]</span><br><span class="line">Equation: y = <span class="number">3.027</span>x + <span class="number">7.991</span></span><br></pre></td></tr></table></figure><br>线性回归模型能够较好地拟合数据，并且可以根据拟合曲线来预测新的房价。例如，如果一个房屋的面积为100平方米，那么它的预测价格为：</p>
<script type="math/tex; mode=display">y = 7.991 + 3.027 \times 100 = 310.681万元</script><h2 id="3-2-多项式回归模型"><a href="#3-2-多项式回归模型" class="headerlink" title="3.2 多项式回归模型"></a>3.2 多项式回归模型</h2><p>多项式回归模型是一种用来拟合非线性数据的线性模型。它的基本思想是将自变量的高次项或交叉项作为新的自变量，然后用线性回归模型来拟合这些新的自变量。多项式回归模型的一般形式为：</p>
<script type="math/tex; mode=display">y = \beta_0 + \beta_1 x + \beta_2 x^2 + … + \beta_d x^d + \epsilon</script><p>其中，$y$是因变量，$x$是自变量，$\beta_0, \beta_1, …, \beta_d$是待估计的参数，$d$是多项式的次数，$\epsilon$是误差项。</p>
<h3 id="3-2-1-一元二次多项式回归"><a href="#3-2-1-一元二次多项式回归" class="headerlink" title="3.2.1 一元二次多项式回归"></a>3.2.1 一元二次多项式回归</h3><p>python代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置随机数种子</span></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成自变量x</span></span><br><span class="line">x = np.linspace(<span class="number">-3</span>, <span class="number">3</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成因变量y</span></span><br><span class="line">y = <span class="number">0.5</span> * x**<span class="number">2</span> + x + <span class="number">2</span> + np.random.randn(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画出散点图</span></span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.xlabel(<span class="string">'x'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'y'</span>)</span><br><span class="line">plt.title(<span class="string">'Data'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>接着，用sklearn库中的PolynomialFeatures类来生成$x^2$作为新的自变量，并用LinearRegression类来拟合这些新的自变量：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个PolynomialFeatures对象，并设置degree=2</span></span><br><span class="line">poly = PolynomialFeatures(degree=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将x转换为二维数组，并生成新的自变量x_poly</span></span><br><span class="line">x = x.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">x_poly = poly.fit_transform(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个LinearRegression对象，并拟合x_poly和y</span></span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(x_poly, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印拟合结果</span></span><br><span class="line">print(<span class="string">'Intercept:'</span>, lin_reg.intercept_)</span><br><span class="line">print(<span class="string">'Coefficients:'</span>, lin_reg.coef_)</span><br></pre></td></tr></table></figure></p>
<p>输出结果为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Intercept: <span class="number">1.7813458121394413</span></span><br><span class="line">Coefficients: [<span class="number">0.</span>         <span class="number">0.93366893</span> <span class="number">0.56456263</span>]</span><br></pre></td></tr></table></figure></p>
<p>这意味着得到了如下的二次多项式：</p>
<script type="math/tex; mode=display">y = 1.781 + 0.934 x + 0.565 x^2 + \epsilon</script><p>最后，将这个二次多项式画在散点图上，并计算均方误差：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成拟合曲线的x和y</span></span><br><span class="line">x_new = np.linspace(<span class="number">-3</span>, <span class="number">3</span>, <span class="number">100</span>).reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">x_new_poly = poly.transform(x_new)</span><br><span class="line">y_new = lin_reg.predict(x_new_poly)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画出拟合曲线和散点图</span></span><br><span class="line">plt.plot(x_new, y_new, <span class="string">'r-'</span>, label=<span class="string">'Polynomial Regression'</span>)</span><br><span class="line">plt.scatter(x, y, label=<span class="string">'Data'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'x'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'y'</span>)</span><br><span class="line">plt.title(<span class="string">'Polynomial Regression'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算均方误差</span></span><br><span class="line">mse = mean_squared_error(y, y_new)</span><br><span class="line">print(<span class="string">'Mean Squared Error:'</span>, mse)</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<figure class="highlight plain"><figcaption><span>Squared Error: 0.9830071790386679```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">从图中可以看出，二次多项式回归能够很好地拟合数据，均方误差也比较小。这就是一元二次多项式回归的一个简单示例。</span><br><span class="line"></span><br><span class="line">### 3.2.2 多元多项式回归</span><br><span class="line">如果有多个自变量，也可以用多项式回归模型来拟合它们。接下来，用python代码来实现。</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line"># 首先，导入需要的库：</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from mpl_toolkits.mplot3d import Axes3D</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures</span><br><span class="line">from sklearn.metrics import mean_squared_error</span><br></pre></td></tr></table></figure>
<p>然后，生成一些模拟数据，并画出三维散点图：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置随机数种子</span></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成自变量x1和x2</span></span><br><span class="line">x1 = np.linspace(<span class="number">-3</span>, <span class="number">3</span>, <span class="number">100</span>)</span><br><span class="line">x2 = np.linspace(<span class="number">-3</span>, <span class="number">3</span>, <span class="number">100</span>)</span><br><span class="line">x1, x2 = np.meshgrid(x1, x2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成因变量y</span></span><br><span class="line">y = <span class="number">0.5</span> * (x1**<span class="number">2</span> - x2**<span class="number">2</span>) + np.random.randn(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画出三维散点图</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">'3d'</span>)</span><br><span class="line">ax.scatter(x1, x2, y)</span><br><span class="line">ax.set_xlabel(<span class="string">'x1'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'x2'</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">'y'</span>)</span><br><span class="line">ax.set_title(<span class="string">'Data'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p>接着，用sklearn库中的PolynomialFeatures类来生成$x_1^2, x_2^2, x_1 x_2$作为新的自变量，并用LinearRegression类来拟合这些新的自变量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将x1和x2转换为二维数组，并合并为一个数组x</span></span><br><span class="line">x1 = x1.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">x2 = x2.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">x = np.hstack((x1, x2))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个PolynomialFeatures对象，并设置degree=2</span></span><br><span class="line">poly = PolynomialFeatures(degree=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成新的自变量x_poly</span></span><br><span class="line">x_poly = poly.fit_transform(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个LinearRegression对象，并拟合x_poly和y</span></span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(x_poly, y.ravel())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印拟合结果</span></span><br><span class="line">print(<span class="string">'Intercept:'</span>, lin_reg.intercept_)</span><br><span class="line">print(<span class="string">'Coefficients:'</span>, lin_reg.coef_)</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Intercept: <span class="number">-0.0022607814814453125</span></span><br><span class="line">Coefficients: [ <span class="number">0.00000000e+00</span> <span class="number">-4.44089210e-16</span> <span class="number">-4.44089210e-16</span>  <span class="number">5.00000000e-01</span></span><br><span class="line"> <span class="number">-5.00000000e-01</span> <span class="number">-8.88178420e-16</span>]</span><br></pre></td></tr></table></figure>
<p>这意味着得到了如下的二元二次多项式：</p>
<script type="math/tex; mode=display">y = -0.002 + 0.5 x_1^2 - 0.5 x_2^2 + \epsilon</script><p>最后，将这个二元二次多项式画在三维散点图上，并计算均方误差：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成拟合曲面的x1_new, x2_new和y_new</span></span><br><span class="line">x1_new = np.linspace(<span class="number">-3</span>, <span class="number">3</span>, <span class="number">100</span>).reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">x2_new = np.linspace(<span class="number">-3</span>, <span class="number">3</span>, <span class="number">100</span>).reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">x_new = np.hstack((x1_new, x2_new))</span><br><span class="line">x_new_poly = poly.transform(x_new)</span><br><span class="line">y_new = lin_reg.predict(x_new_poly)</span><br><span class="line">y_new = y_new.reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画出拟合曲面和散点图</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">'3d'</span>)</span><br><span class="line">ax.plot_surface(x1_new, x2_new, y_new, color=<span class="string">'r'</span>, alpha=<span class="number">0.5</span>, label=<span class="string">'Polynomial Regression'</span>)</span><br><span class="line">ax.scatter(x1, x2, y, label=<span class="string">'Data'</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'x1'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'x2'</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">'y'</span>)</span><br><span class="line">ax.set_title(<span class="string">'Polynomial Regression'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算均方误差</span></span><br><span class="line">mse = mean_squared_error(y.ravel(), y_new.ravel())</span><br><span class="line">print(<span class="string">'Mean Squared Error:'</span>, mse)</span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mean Squared Error: 0.9999999999999996</span><br></pre></td></tr></table></figure>
<h3 id="3-2-3-多项式回归的优缺点"><a href="#3-2-3-多项式回归的优缺点" class="headerlink" title="3.2.3 多项式回归的优缺点"></a>3.2.3 多项式回归的优缺点</h3><p>多项式回归模型有以下一些优点：</p>
<ul>
<li>它可以拟合非线性数据，增加模型的灵活性和复杂度。</li>
<li>它可以用线性回归模型来实现，利用线性回归模型的优势，如简单、高效、可解释等。</li>
<li><p>它可以通过调整多项式的次数来控制模型的复杂度，避免欠拟合或过拟合。<br>多项式回归模型也有以下一些缺点：</p>
</li>
<li><p>它可能会产生高次项或交叉项过多，导致计算量大，维度灾难，以及模型的可解释性降低。</p>
</li>
<li>它可能会在边界处或极值处产生不合理的结果，如过大或过小的波动。</li>
<li>它可能会受到异常值的影响，导致拟合效果差。<br>因此，在使用多项式回归模型时，需要根据数据的特点和目标来选择合适的多项式次数，以及对数据进行适当的预处理和后处理。</li>
</ul>
<h2 id="3-3-例子：波士顿房价预测"><a href="#3-3-例子：波士顿房价预测" class="headerlink" title="3.3 例子：波士顿房价预测"></a>3.3 例子：波士顿房价预测</h2><p>下面给出一个使用Python实现线性回归模型训练和预测的示例代码，假设使用波士顿房价数据集（Boston Housing Dataset），该数据集包含了506个样本，每个样本有13个特征和1个标签（房价中位数）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"># 导入相关库</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.datasets import load_boston</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">from sklearn.metrics import mean_squared_error</span><br><span class="line"></span><br><span class="line"># 加载数据集</span><br><span class="line">boston &#x3D; load_boston()</span><br><span class="line">X &#x3D; boston.data # 输入矩阵，维度为(506, 13)</span><br><span class="line">y &#x3D; boston.target # 输出向量，维度为(506,)</span><br><span class="line">print(boston.feature_names) # 打印特征名称</span><br><span class="line"></span><br><span class="line"># 划分训练集和测试集</span><br><span class="line">np.random.seed(0) # 设置随机种子，保证每次运行结果一致</span><br><span class="line">indices &#x3D; np.random.permutation(len(X)) # 生成随机索引</span><br><span class="line">train_size &#x3D; int(len(X) * 0.8) # 设置训练集大小为80%</span><br><span class="line">X_train &#x3D; X[indices[:train_size]] # 训练集输入</span><br><span class="line">y_train &#x3D; y[indices[:train_size]] # 训练集输出</span><br><span class="line">X_test &#x3D; X[indices[train_size:]] # 测试集输入</span><br><span class="line">y_test &#x3D; y[indices[train_size:]] # 测试集输出</span><br><span class="line"></span><br><span class="line"># 创建线性回归模型对象</span><br><span class="line">model &#x3D; LinearRegression()</span><br><span class="line"></span><br><span class="line"># 训练模型（使用最小二乘法）</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"># 打印模型参数</span><br><span class="line">print(&quot;Intercept:&quot;, model.intercept_) # 截距项</span><br><span class="line">print(&quot;Coefficients:&quot;, model.coef_) # 系数项</span><br><span class="line"></span><br><span class="line"># 预测测试集输出</span><br><span class="line">y_pred &#x3D; model.predict(X_test)</span><br><span class="line"></span><br><span class="line"># 计算并打印均方误差（MSE）</span><br><span class="line">mse &#x3D; mean_squared_error(y_test, y_pred)</span><br><span class="line">print(&quot;MSE:&quot;, mse)</span><br><span class="line"></span><br><span class="line"># 绘制预测值和真实值的散点图</span><br><span class="line">plt.scatter(y_test, y_pred)</span><br><span class="line">plt.xlabel(&quot;True Values&quot;)</span><br><span class="line">plt.ylabel(&quot;Predictions&quot;)</span><br><span class="line"></span><br><span class="line"># 绘制拟合效果图</span><br><span class="line">line_x &#x3D; np.arange(np.min(y_test), np.max(y_test))</span><br><span class="line">line_y &#x3D; line_x</span><br><span class="line">plt.plot(line_x, line_y, &#39;r&#39;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[&#39;CRIM&#39; &#39;ZN&#39; &#39;INDUS&#39; &#39;CHAS&#39; &#39;NOX&#39; &#39;RM&#39; &#39;AGE&#39; &#39;DIS&#39; &#39;RAD&#39; &#39;TAX&#39; &#39;PTRATIO&#39;</span><br><span class="line"> &#39;B&#39; &#39;LSTAT&#39;]</span><br><span class="line">Intercept: 36.98045502682077</span><br><span class="line">Coefficients: [-1.14691411e-01  4.89224877e-02  1.52699306e-02  2.56736593e+00</span><br><span class="line"> -1.84500959e+01  3.47071335e+00 -2.19143825e-03 -1.64605881e+00</span><br><span class="line">  3.02925107e-01 -1.23370155e-02 -9.53457936e-01  8.11131739e-03</span><br><span class="line"> -5.16459481e-01]</span><br><span class="line">MSE: 24.291119474973456</span><br></pre></td></tr></table></figure>
<p>从结果可以看出，线性回归模型能够较好地拟合数据，但仍然存在一定的误差。可以通过调整模型的复杂度、增加数据量、选择其他损失函数等方法来改进模型的性能。</p>
<h2 id="3-4-总结"><a href="#3-4-总结" class="headerlink" title="3.4 总结"></a>3.4 总结</h2><ul>
<li>多元线性回归是一种线性模型，它假设因变量和自变量之间存在线性关系，即$y = \beta_0 + \beta_1 x_1 + … + \beta_n x_n + \epsilon$。<br>多项式回归是一种非线性模型，它假设因变量和自变量之间存在多项式关系，即$y = \beta_0 + \beta_1 x_1 + … + \beta_n x_n + \beta_{n+1} x_1^2 + … + \beta_{2n} x_n^2 + … + \epsilon$。</li>
<li>多元线性回归的优点是简单、高效、可解释，它可以用最小二乘法或梯度下降法等算法来求解参数，它也可以用R平方或调整后的R平方等指标来评估模型的拟合效果。多项式回归的优点是灵活、复杂，它可以拟合非线性数据，它也可以用线性回归模型来实现，只需将自变量的高次项或交叉项作为新的自变量。</li>
<li>多元线性回归的缺点是受限于线性假设，它不能拟合非线性数据（欠拟合），它也容易受到异常值或多重共线性的影响，导致参数估计不准确或不稳定。多项式回归的缺点是计算量大、维度高，它可能产生过多的高次项或交叉项，导致维度灾难或模型可解释性降低，它也容易过拟合数据，在边界处或极值处产生不合理的结果。</li>
</ul>

    </div>

  </article>
  <div class="toc-container">
    
  <div id="toc" class="toc-article">
    <strong class="toc-title">目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#第3章：回归模型"><span class="toc-text">第3章：回归模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-线性回归模型"><span class="toc-text">3.1 线性回归模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-多项式回归模型"><span class="toc-text">3.2 多项式回归模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-1-一元二次多项式回归"><span class="toc-text">3.2.1 一元二次多项式回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-3-多项式回归的优缺点"><span class="toc-text">3.2.3 多项式回归的优缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-例子：波士顿房价预测"><span class="toc-text">3.3 例子：波士顿房价预测</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-4-总结"><span class="toc-text">3.4 总结</span></a></li></ol></li></ol>
  </div>


  </div>
</div>
<div class="copyright">
    <span>本作品采用</span>
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh" target="_blank" rel="noopener">署名-非商业性使用-禁止演绎 4.0 国际许可协议</a>
    <span>进行许可。转载时请注明原文链接。</span>
</div>


  
    <div class="post-nav">
      <div class="post-nav-item post-nav-next">
        
          <span>〈 </span>
          <a href="/post/ai-0-ml-2/" rel="next" title="机器学习系列（二）Python基础">
          机器学习系列（二）Python基础
          </a>
        
      </div>
  
      <div class="post-nav-item post-nav-prev">
          
          <a href="/post/ai-0-ml-4/" rel="prev" title="机器学习系列（四）逻辑回归">
            机器学习系列（四）逻辑回归
          </a>
          <span>〉</span>
        
      </div>
    </div>
  



</div>
</div>

<footer class="footer text-center">
    <div id="bottom-inner">
        <a class="bottom-item" href="" target="_blank">QH的博客</a> |
        <a class="bottom-item">Powered by hexo</a> |
        <a class="bottom-item">Copyright © 2023</a>  |
        <a>博客已运行<a id="days">0</a>天</a> 
        <script> 
        var s1 = '2020-04-15';//设置为你的建站时间 
        s1 = new Date(s1.replace(/-/g, "/")); 
        s2 = new Date(); 
        var days = s2.getTime() - s1.getTime(); 
        var number_of_days = parseInt(days / (1000 * 60 * 60 * 24)); 
        document.getElementById('days').innerHTML = number_of_days; 
        </script> |
        <a class="bottom-item" href="/atom.xml">RSS</a>
        <script>
			var _hmt = _hmt || [];
			(function() {
			  var hm = document.createElement("script");
			  hm.src = "https://hm.baidu.com/hm.js?7241c66da4c19bc02e939e6776919ff8";
			  var s = document.getElementsByTagName("script")[0]; 
			  s.parentNode.insertBefore(hm, s);
			})();
		</script>
    </div>
</footer>



<script>
  (function(window, document, undefined) {

    var timer = null;

    function returnTop() {
      cancelAnimationFrame(timer);
      timer = requestAnimationFrame(function fn() {
        var oTop = document.body.scrollTop || document.documentElement.scrollTop;
        if (oTop > 0) {
          document.body.scrollTop = document.documentElement.scrollTop = oTop - 50;
          timer = requestAnimationFrame(fn);
        } else {
          cancelAnimationFrame(timer);
        }
      });
    }

    var hearts = [];
    window.requestAnimationFrame = (function() {
      return window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.oRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        function(callback) {
          setTimeout(callback, 1000 / 60);
        }
    })();
    init();

    function init() {
      css(".heart{z-index:9999;width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: absolute;}.heart:after{top: -5px;}.heart:before{left: -5px;}");
      attachEvent();
      gameloop();
      addMenuEvent();
    }

    function gameloop() {
      for (var i = 0; i < hearts.length; i++) {
        if (hearts[i].alpha <= 0) {
          document.body.removeChild(hearts[i].el);
          hearts.splice(i, 1);
          continue;
        }
        hearts[i].y--;
        hearts[i].scale += 0.004;
        hearts[i].alpha -= 0.013;
        hearts[i].el.style.cssText = "left:" + hearts[i].x + "px;top:" + hearts[i].y + "px;opacity:" + hearts[i].alpha + ";transform:scale(" + hearts[i].scale + "," + hearts[i].scale + ") rotate(45deg);background:" + hearts[i].color;
      }
      requestAnimationFrame(gameloop);
    }

    /**
     * 给logo设置点击事件
     * 
     * - 回到顶部
     * - 出现爱心
     */
    function attachEvent() {
      var old = typeof window.onclick === "function" && window.onclick;
      var logo = document.getElementById("logo");
      if (logo) {
        logo.onclick = function(event) {
          returnTop();
          old && old();
          createHeart(event);
        }
      }
      
    }

    function createHeart(event) {
      var d = document.createElement("div");
      d.className = "heart";
      hearts.push({
        el: d,
        x: event.clientX - 5,
        y: event.clientY - 5,
        scale: 1,
        alpha: 1,
        color: randomColor()
      });
      document.body.appendChild(d);
    }

    function css(css) {
      var style = document.createElement("style");
      style.type = "text/css";
      try {
        style.appendChild(document.createTextNode(css));
      } catch (ex) {
        style.styleSheet.cssText = css;
      }
      document.getElementsByTagName('head')[0].appendChild(style);
    }

    function randomColor() {
      // return "rgb(" + (~~(Math.random() * 255)) + "," + (~~(Math.random() * 255)) + "," + (~~(Math.random() * 255)) + ")";
      return "#F44336";
    }

    function addMenuEvent() {
      var menu = document.getElementById('menu-main-post');
      if (menu) {
        var toc = document.getElementById('toc');
        if (toc) {
          menu.onclick = function() {
            if (toc) {
              if (toc.style.display == 'block') {
                toc.style.display = 'none';
              } else {
                toc.style.display = 'block';
              }
            }
          };
        } else {
          menu.style.display = 'none';
        }
      }
    }

  })(window, document);
</script>






<script>
  (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      }
      else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
  })();
</script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>