<!DOCTYPE html>
<html lang="zh-CN">


<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
  <meta name="theme-color" content="#202020"/>
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  
    <meta name="keywords" content="机器学习,深度学习,强化学习," />
  

  
    <meta name="description" content="心向大海" />
  
  
  
  <link rel="icon" type="image/x-icon" href="/images/favicon.ico">
  
  <title>机器学习系列（八）决策树算法 - 心向大海</title>
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="/css/pure-min.css">
    
      <link rel="stylesheet" href="/css/xoxo.css">
    
  
<meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="心向大海" type="application/atom+xml">
</head>


<body>
<div class="nav-container">
<nav class="home-menu pure-menu pure-menu-horizontal">
  <a class="pure-menu-heading" href="/">
    
      <img class="avatar" src="https://smiler666.github.io/images/favicon.ico">
    
    <span class="title" style="text-transform:none">心向大海</span>
  </a>

  <ul class="pure-menu-list clearfix">
      
          
            
              <li class="pure-menu-item"><a href="/" class="pure-menu-link">首页</a></li>
            
          
      
          
            
              <li class="pure-menu-item"><a href="/tags/教程" class="pure-menu-link">教程</a></li>
            
          
      
          
            
              <li class="pure-menu-item"><a href="/archives" class="pure-menu-link">文章</a></li>
            
          
      
          
            
              <li class="pure-menu-item"><a href="/post/share-1/" class="pure-menu-link">工具</a></li>
            
          
      
          
            
              <li class="pure-menu-item"><a href="/about" class="pure-menu-link">关于</a></li>
            
          
      
          
            
              <li class="pure-menu-item"><a href="/search" class="pure-menu-link">搜索</a></li>
            
          
      
  </ul>
   
</nav>

</div>

<div class="container" id="content-outer">
<div class="inner" id="content-inner">
<div class="post-container">
  <article class="post" id="post">
    <header class="post-header text-center">
      <h1 class="title">
        机器学习系列（八）决策树算法
      </h1>
      <span>
        
        <time class="time" datetime="2021-03-29T04:20:00.000Z">
        2021-03-29
      </time>
        
      </span>
      <span class="slash">/</span>
      <span class="post-meta">
      <span class="post-tags">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" rel="tag">强化学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li></ul>
      </span>
    </span>
      <span class="slash">/</span>
      <span class="read">阅读耗时 8 分钟</span>
    </header>

    <div class="post-content">
      <a id="more"></a>
<h1 id="第8章：机器学习决策树"><a href="#第8章：机器学习决策树" class="headerlink" title="第8章：机器学习决策树"></a>第8章：机器学习决策树</h1><p>决策树是一种常用的机器学习算法，用于解决分类和回归问题。它是一种基于树状结构的模型，通过对特征的划分和决策节点的选择来进行预测。</p>
<h2 id="8-1-算法简介"><a href="#8-1-算法简介" class="headerlink" title="8.1 算法简介"></a>8.1 算法简介</h2><p>决策树算法的基本思想是从根节点开始，根据特征值对数据集进行划分，形成子节点。划分依据通常是通过计算信息增益或者基尼系数来选择最优的特征。信息增益表示在划分前后，分类的不确定性减少的程度；基尼系数则表示在划分前后，数据集中样本被错误分类的概率。</p>
<p>决策树的生成过程可以通过递归的方式进行，直到满足停止条件，如节点中的样本全部属于同一类别或者特征用尽。生成的决策树可以用于对新样本进行分类或者回归预测。</p>
<p>决策树算法的优点包括易于理解和解释，可以处理离散和连续特征，具有较好的可解释性。然而，决策树也有一些缺点，如容易过拟合、对噪声敏感等。</p>
<h2 id="8-2-算法公式"><a href="#8-2-算法公式" class="headerlink" title="8.2 算法公式"></a>8.2 算法公式</h2><h3 id="8-2-1-信息增益"><a href="#8-2-1-信息增益" class="headerlink" title="8.2.1 信息增益"></a>8.2.1 信息增益</h3><p>信息增益用于选择最优的特征进行划分，可以通过以下公式计算：</p>
<script type="math/tex; mode=display">
Information\_Gain(D, A) = Entropy(D) - \sum_{v \in Values(A)} \frac{|D_v|}{|D|}Entropy(D_v)</script><p>其中，$D$是当前节点的数据集，$A$是待选择的特征，<code>Values(A)</code>是特征$A$的所有取值，$D_v$是特征$A$取值为$v$时的子数据集，$|D|$是数据集$D$中的样本数量，$|D_v|$是子数据集$D_v$中的样本数量，<code>Entropy(D)</code>表示数据集$D$的熵，可以通过以下公式计算：</p>
<script type="math/tex; mode=display">
Entropy(D) = - \sum_{i=1}^{|C|} p_i * log_2(p_i)</script><p>其中，$C$是数据集$D$中的所有类别，$p_i$是类别$i$在数据集$D$中的占比。</p>
<h3 id="8-2-2-基尼系数"><a href="#8-2-2-基尼系数" class="headerlink" title="8.2.2 基尼系数"></a>8.2.2 基尼系数</h3><p>基尼系数用于选择最优的特征进行划分，可以通过以下公式计算：</p>
<script type="math/tex; mode=display">
Gini_Index(D, A) = \sum_{v in Values(A)} \frac{|D_v|}{|D|} Gini(D_v)</script><p>其中，$D$是当前节点的数据集，$A$是待选择的特征，<code>Values(A)</code>是特征$A$的所有取值，$D_v$是特征$A$取值为$v$时的子数据集，$|D|$是数据集$D$中的样本数量，$|D_v|$是子数据集$D_v$中的样本数量，<code>Gini(D_v)</code>表示子数据集$D_v$的基尼指数，可以通过以下公式计算：</p>
<script type="math/tex; mode=display">
Gini(D_v) = 1 - \sum_{i=1}^{|C|} (p_i)^2</script><p>其中，$C$是子数据集$D_v$中的所有类别，$p_i$是类别$i$在子数据集$D_v$中的占比。</p>
<h2 id="8-3-Python代码"><a href="#8-3-Python代码" class="headerlink" title="8.3 Python代码"></a>8.3 Python代码</h2><p>下面是一个使用Python的示例代码，展示如何使用sklearn库构建决策树模型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建决策树分类器</span></span><br><span class="line">clf = DecisionTreeClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用训练数据拟合模型</span></span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用模型进行预测</span></span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算模型的准确率</span></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line">print(<span class="string">"模型准确率："</span>, accuracy)</span><br></pre></td></tr></table></figure></p>
<h2 id="8-4-例子"><a href="#8-4-例子" class="headerlink" title="8.4 例子"></a>8.4 例子</h2><p>下面以一个简单的二分类问题为例，使用Python代码演示如何使用决策树算法进行分类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建示例数据集</span></span><br><span class="line">data = &#123;<span class="string">'年龄'</span>: [<span class="number">18</span>, <span class="number">25</span>, <span class="number">30</span>, <span class="number">35</span>, <span class="number">40</span>, <span class="number">45</span>],</span><br><span class="line">        <span class="string">'收入'</span>: [<span class="string">'低'</span>, <span class="string">'低'</span>, <span class="string">'中'</span>, <span class="string">'中'</span>, <span class="string">'高'</span>, <span class="string">'高'</span>],</span><br><span class="line">        <span class="string">'性别'</span>: [<span class="string">'男'</span>, <span class="string">'女'</span>, <span class="string">'男'</span>, <span class="string">'女'</span>, <span class="string">'男'</span>, <span class="string">'女'</span>],</span><br><span class="line">        <span class="string">'是否购车'</span>: [<span class="string">'否'</span>, <span class="string">'否'</span>, <span class="string">'是'</span>, <span class="string">'是'</span>, <span class="string">'是'</span>, <span class="string">'否'</span>]&#125;</span><br><span class="line">df = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将特征进行数值化</span></span><br><span class="line">df[<span class="string">'收入'</span>] = df[<span class="string">'收入'</span>].map(&#123;<span class="string">'低'</span>: <span class="number">0</span>, <span class="string">'中'</span>: <span class="number">1</span>, <span class="string">'高'</span>: <span class="number">2</span>&#125;)</span><br><span class="line">df[<span class="string">'性别'</span>] = df[<span class="string">'性别'</span>].map(&#123;<span class="string">'男'</span>: <span class="number">0</span>, <span class="string">'女'</span>: <span class="number">1</span>&#125;)</span><br><span class="line">df[<span class="string">'是否购车'</span>] = df[<span class="string">'是否购车'</span>].map(&#123;<span class="string">'否'</span>: <span class="number">0</span>, <span class="string">'是'</span>: <span class="number">1</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分离特征和标签</span></span><br><span class="line">X_train = df[[<span class="string">'年龄'</span>, <span class="string">'收入'</span>, <span class="string">'性别'</span>]]</span><br><span class="line">y_train = df[<span class="string">'是否购车'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建决策树分类器</span></span><br><span class="line">clf = DecisionTreeClassifier(criterion=<span class="string">'gini'</span>)</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行预测</span></span><br><span class="line">new_data = [[<span class="number">28</span>, <span class="number">1</span>, <span class="number">0</span>]]  <span class="comment"># 新样本特征</span></span><br><span class="line">y_pred = clf.predict(new_data)</span><br><span class="line">print(<span class="string">'是否购车:'</span>, y_pred)  <span class="comment"># 输出预测结果</span></span><br></pre></td></tr></table></figure>
<p>以上代码首先创建了一个包含年龄、收入、性别和是否购车标签的数据集。然后使用<code>DecisionTreeClassifier</code>类创建了一个基于基尼系数的决策树分类器，并用训练数据进行了拟合。最后，通过<code>predict</code>方法对新样本进行预测，并输出了预测结果。</p>
<h2 id="8-5-总结"><a href="#8-5-总结" class="headerlink" title="8.5 总结"></a>8.5 总结</h2><p>决策树是一种常用的机器学习算法，通过对特征的划分和决策节点的选择来进行预测。其基本思想是从根节点开始，通过信息增益或基尼系数等指标选择最优的特征进行划分，形成子节点，直到满足停止条件。决策树具有易于理解和解释的优点，可以处理离散和连续特征，但也存在过拟合和对噪声敏感的缺点。</p>
<p>在实际应用中，可以根据具体问题选择合适的特征选择方法、停止条件和参数调优，以获取更好的模型性能。</p>

    </div>

  </article>
  <div class="toc-container">
    
  <div id="toc" class="toc-article">
    <strong class="toc-title">目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#第8章：机器学习决策树"><span class="toc-text">第8章：机器学习决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#8-1-算法简介"><span class="toc-text">8.1 算法简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-2-算法公式"><span class="toc-text">8.2 算法公式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-1-信息增益"><span class="toc-text">8.2.1 信息增益</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-2-基尼系数"><span class="toc-text">8.2.2 基尼系数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-3-Python代码"><span class="toc-text">8.3 Python代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-4-例子"><span class="toc-text">8.4 例子</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-5-总结"><span class="toc-text">8.5 总结</span></a></li></ol></li></ol>
  </div>


  </div>
</div>
<div class="copyright">
    <span>本作品采用</span>
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh" target="_blank" rel="noopener">署名-非商业性使用-禁止演绎 4.0 国际许可协议</a>
    <span>进行许可。转载时请注明原文链接。</span>
</div>


  
    <div class="post-nav">
      <div class="post-nav-item post-nav-next">
        
          <span>〈 </span>
          <a href="/post/ai-0-ml-7/" rel="next" title="机器学习系列（七）支持向量机">
          机器学习系列（七）支持向量机
          </a>
        
      </div>
  
      <div class="post-nav-item post-nav-prev">
          
          <a href="/post/ai-0-ml-9/" rel="prev" title="机器学习系列（九）无监督学习之聚类">
            机器学习系列（九）无监督学习之聚类
          </a>
          <span>〉</span>
        
      </div>
    </div>
  



</div>
</div>

<footer class="footer text-center">
    <div id="bottom-inner">
        <a class="bottom-item" href="" target="_blank">心向大海</a> |
        <a class="bottom-item">Powered by hexo</a> |
        <a class="bottom-item">Copyright © 2023</a>  |
        <a>博客已运行<a id="days">0</a>天</a> 
        <script> 
        var s1 = '2020-04-15';//设置为你的建站时间 
        s1 = new Date(s1.replace(/-/g, "/")); 
        s2 = new Date(); 
        var days = s2.getTime() - s1.getTime(); 
        var number_of_days = parseInt(days / (1000 * 60 * 60 * 24)); 
        document.getElementById('days').innerHTML = number_of_days; 
        </script> |
        <a class="bottom-item" href="/atom.xml">RSS</a>
        <script>
			var _hmt = _hmt || [];
			(function() {
			  var hm = document.createElement("script");
			  hm.src = "https://hm.baidu.com/hm.js?7241c66da4c19bc02e939e6776919ff8";
			  var s = document.getElementsByTagName("script")[0]; 
			  s.parentNode.insertBefore(hm, s);
			})();
		</script>
    </div>
</footer>



<script>
  (function(window, document, undefined) {

    var timer = null;

    function returnTop() {
      cancelAnimationFrame(timer);
      timer = requestAnimationFrame(function fn() {
        var oTop = document.body.scrollTop || document.documentElement.scrollTop;
        if (oTop > 0) {
          document.body.scrollTop = document.documentElement.scrollTop = oTop - 50;
          timer = requestAnimationFrame(fn);
        } else {
          cancelAnimationFrame(timer);
        }
      });
    }

    var hearts = [];
    window.requestAnimationFrame = (function() {
      return window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.oRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        function(callback) {
          setTimeout(callback, 1000 / 60);
        }
    })();
    init();

    function init() {
      css(".heart{z-index:9999;width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: absolute;}.heart:after{top: -5px;}.heart:before{left: -5px;}");
      attachEvent();
      gameloop();
      addMenuEvent();
    }

    function gameloop() {
      for (var i = 0; i < hearts.length; i++) {
        if (hearts[i].alpha <= 0) {
          document.body.removeChild(hearts[i].el);
          hearts.splice(i, 1);
          continue;
        }
        hearts[i].y--;
        hearts[i].scale += 0.004;
        hearts[i].alpha -= 0.013;
        hearts[i].el.style.cssText = "left:" + hearts[i].x + "px;top:" + hearts[i].y + "px;opacity:" + hearts[i].alpha + ";transform:scale(" + hearts[i].scale + "," + hearts[i].scale + ") rotate(45deg);background:" + hearts[i].color;
      }
      requestAnimationFrame(gameloop);
    }

    /**
     * 给logo设置点击事件
     * 
     * - 回到顶部
     * - 出现爱心
     */
    function attachEvent() {
      var old = typeof window.onclick === "function" && window.onclick;
      var logo = document.getElementById("logo");
      if (logo) {
        logo.onclick = function(event) {
          returnTop();
          old && old();
          createHeart(event);
        }
      }
      
    }

    function createHeart(event) {
      var d = document.createElement("div");
      d.className = "heart";
      hearts.push({
        el: d,
        x: event.clientX - 5,
        y: event.clientY - 5,
        scale: 1,
        alpha: 1,
        color: randomColor()
      });
      document.body.appendChild(d);
    }

    function css(css) {
      var style = document.createElement("style");
      style.type = "text/css";
      try {
        style.appendChild(document.createTextNode(css));
      } catch (ex) {
        style.styleSheet.cssText = css;
      }
      document.getElementsByTagName('head')[0].appendChild(style);
    }

    function randomColor() {
      // return "rgb(" + (~~(Math.random() * 255)) + "," + (~~(Math.random() * 255)) + "," + (~~(Math.random() * 255)) + ")";
      return "#F44336";
    }

    function addMenuEvent() {
      var menu = document.getElementById('menu-main-post');
      if (menu) {
        var toc = document.getElementById('toc');
        if (toc) {
          menu.onclick = function() {
            if (toc) {
              if (toc.style.display == 'block') {
                toc.style.display = 'none';
              } else {
                toc.style.display = 'block';
              }
            }
          };
        } else {
          menu.style.display = 'none';
        }
      }
    }

  })(window, document);
</script>






<script>
  (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      }
      else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
  })();
</script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>